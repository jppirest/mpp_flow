{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "\n",
    "  def __init__(self, size):\n",
    "    self.size = size\n",
    "    self.stack = []\n",
    "\n",
    "  def push(self, item):\n",
    "    if len(self.stack) >= self.size:\n",
    "      self.pop()\n",
    "    self.stack.append(item)\n",
    "\n",
    "  def pop(self):\n",
    "    if self.stack:\n",
    "      return self.stack.pop(0)\n",
    "    else:\n",
    "      return None\n",
    "\n",
    "  def __repr__(self):\n",
    "    return repr(self.stack)\n",
    "  \n",
    "  def copy(self):\n",
    "    return self.stack.copy()\n",
    "  \n",
    "  def __iter__(self):\n",
    "    return iter(self.stack[::-1])\n",
    "  \n",
    "  def full(self):\n",
    "    return len(self.stack) == self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sweep():\n",
    "  def __init__(self, processes, memory_dim):\n",
    "    self.processes = processes\n",
    "    self.n_processes = len(processes)\n",
    "    self.memory_dim = memory_dim\n",
    "\n",
    "  def make_dict(self):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HawkesSweep(Sweep):\n",
    "\n",
    "  def make_dict(self):\n",
    "    dic = {}\n",
    "    for i in range(self.n_processes):\n",
    "      target = self.processes[i]\n",
    "      dic[i] = {}\n",
    "      for j in range(self.n_processes):\n",
    "        cause = self.processes[j]\n",
    "        dic[i][j] = self.sweep(target, cause)\n",
    "\n",
    "    return dic\n",
    "\n",
    "  def sweep(self, pa, pc):\n",
    "    events = []\n",
    "    pa_indices = []\n",
    "\n",
    "    for i, ia in enumerate(pa):\n",
    "      events.append((ia, 'a'))\n",
    "      pa_indices.append(i)\n",
    "\n",
    "    for ic in pc:\n",
    "      events.append((ic, 'c'))\n",
    "\n",
    "    lim = self.memory_dim\n",
    "\n",
    "    events.sort()\n",
    "    mem = Memory(lim)\n",
    "    ret = []\n",
    "\n",
    "    for t, e in events:\n",
    "      if e == 'c':\n",
    "        mem.push(t)\n",
    "\n",
    "      if e == 'a':\n",
    "        # Memory is not full yet\n",
    "        if not mem.full():\n",
    "          pp = [-1] * lim\n",
    "        else:\n",
    "          # Retrieve deltas from this time to the cause times\n",
    "          pp = [t - tc for tc in mem]\n",
    "        ret.append(pp)\n",
    "    return torch.tensor(ret, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {0: tensor([[-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [ 1.,  2.]]),\n",
       "  1: tensor([[-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [-1., -1.]])},\n",
       " 1: {0: tensor([[1., 2.],\n",
       "          [2., 3.],\n",
       "          [3., 4.]]),\n",
       "  1: tensor([[-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [ 1.,  2.]])}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hk = HawkesSweep([[1, 2, 3], [4, 5, 6]], 2)\n",
    "\n",
    "hk.make_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WoldSweep(Sweep):\n",
    "    def construct_wold_dict(self):\n",
    "        dict = {}\n",
    "\n",
    "        events = []\n",
    "        for id, process in enumerate(self.processes):\n",
    "            for t in process:\n",
    "                events.append((t.item(), id))\n",
    "\n",
    "        events.sort()\n",
    "\n",
    "        deltas = {}\n",
    "        last = {}\n",
    "        cur = -1\n",
    "\n",
    "        for t, id in events:\n",
    "            dict[t] = {}\n",
    "            deltas[id] = Memory(self.memory_dim)\n",
    "            last[id] = [0, 0]\n",
    "\n",
    "        for t, id in events:\n",
    "            if t != cur:\n",
    "                \n",
    "                # updating\n",
    "                cur = t\n",
    "                for _id, _delta in deltas.items():\n",
    "                    dict[cur][_id] = _delta.copy()\n",
    "            \n",
    "            last[id][1] = last[id][0]\n",
    "            last[id][0] = t\n",
    "            if last[id][1] != 0:\n",
    "                deltas[id].push(last[id][0] - last[id][1])\n",
    "            \n",
    "        return dict\n",
    "        \n",
    "    # TODO: check idx_start semantics\n",
    "    def make_dict(self):\n",
    "        wold = self.construct_wold_dict()\n",
    "        dic = {}\n",
    "        for i in range(self.n_processes):\n",
    "            target = self.processes[i]\n",
    "            dic[i] = {}\n",
    "            #for j in range(self.n_processes):\n",
    "            #    cause = self.processes[j]\n",
    "            #    dic[i][j] = self.sweep(target, cause)\n",
    "            ret = {}\n",
    "            for _t in target:\n",
    "                t = _t.item()\n",
    "                for j in range(self.n_processes):\n",
    "                    if j not in ret:\n",
    "                        ret[j] = []\n",
    "                    #print(t, j, wold[t][j])\n",
    "                    #return None\n",
    "                    if len(wold[t][j]) < self.memory_dim:\n",
    "                        ret[j].append([-1] * self.memory_dim)\n",
    "                    else:\n",
    "                        ret[j].append(wold[t][j])\n",
    "\n",
    "            #return None\n",
    "            for j in range(self.n_processes):\n",
    "                dic[i][j] = torch.tensor(ret[j], dtype=torch.float)\n",
    "\n",
    "        return dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {0: tensor([[-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [ 1.,  1.],\n",
       "          [ 1.,  1.]]),\n",
       "  1: tensor([[-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [-1., -1.]])},\n",
       " 1: {0: tensor([[-1., -1.],\n",
       "          [ 1.,  1.],\n",
       "          [ 1.,  1.],\n",
       "          [ 1.,  1.],\n",
       "          [ 1.,  1.],\n",
       "          [ 1.,  1.]]),\n",
       "  1: tensor([[-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [ 4.,  4.],\n",
       "          [ 4.,  4.]])}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd = WoldSweep(torch.tensor([[i for i in range(6)], [i for i in range(0, 6*4, 4)]]), 2)\n",
    "\n",
    "wd.make_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuraltpp",
   "language": "python",
   "name": "neuraltpp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
