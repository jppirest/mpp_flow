{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Zk0vK_o0aYw_"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import pandas as pd\n",
    "import os.path\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
    "    device = \"cpu\"\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxvSqjd6aYxB"
   },
   "source": [
    "# Load and pre process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Hyperlink</th>\n",
       "      <th>Blog</th>\n",
       "      <th>PostNb</th>\n",
       "      <th>WeightOfLink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-01 00:04:10</td>\n",
       "      <td>http://ameblo.jp</td>\n",
       "      <td>http://ameblo.jp</td>\n",
       "      <td>149</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-01 00:04:15</td>\n",
       "      <td>http://reddit.com</td>\n",
       "      <td>http://reddit.com</td>\n",
       "      <td>158</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-01 00:04:33</td>\n",
       "      <td>http://pr-inside.com</td>\n",
       "      <td>http://pr-inside.com</td>\n",
       "      <td>213</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-01 00:04:33</td>\n",
       "      <td>http://pr-inside.com</td>\n",
       "      <td>http://pr-inside.com</td>\n",
       "      <td>214</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-01 00:05:00</td>\n",
       "      <td>http://de.answers.yahoo.com</td>\n",
       "      <td>http://de.answers.yahoo.com</td>\n",
       "      <td>268</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date                    Hyperlink  \\\n",
       "0  2009-01-01 00:04:10             http://ameblo.jp   \n",
       "1  2009-01-01 00:04:15            http://reddit.com   \n",
       "2  2009-01-01 00:04:33         http://pr-inside.com   \n",
       "3  2009-01-01 00:04:33         http://pr-inside.com   \n",
       "4  2009-01-01 00:05:00  http://de.answers.yahoo.com   \n",
       "\n",
       "                          Blog  PostNb  WeightOfLink  \n",
       "0             http://ameblo.jp     149           0.5  \n",
       "1            http://reddit.com     158           1.0  \n",
       "2         http://pr-inside.com     213           1.0  \n",
       "3         http://pr-inside.com     214           1.0  \n",
       "4  http://de.answers.yahoo.com     268           1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('ticks.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization and grouping timestamps by `Hyperlink`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3MiUUfO2aYxF"
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('grouped.pkl'):\n",
    "    data['Date'] = data[\"Date\"].apply(pd.to_datetime)\n",
    "    data['Time'] = data['Date'].apply(pd.Timestamp)\n",
    "    data['Time'] = data['Time'].apply(lambda x: x.timestamp())\n",
    "    t_begin = data['Time'].min()\n",
    "    data['Time'] = data['Time'].apply(lambda x : x - t_begin) # Normalization\n",
    "    grouped = data.groupby(['Hyperlink'])['Time'].apply(np.array).reset_index(name='Times')\n",
    "    grouped['Length'] = grouped['Times'].apply(len)\n",
    "    grouped['Times'] = grouped['Times'].apply(np.sort)\n",
    "    grouped.to_pickle('grouped.pkl')\n",
    "else:\n",
    "    grouped = pd.read_pickle('grouped.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hyperlink</th>\n",
       "      <th>Times</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://1.bp.blogspot.com</td>\n",
       "      <td>[180906.0, 182723.0, 182969.0, 184891.0, 18535...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://2.bp.blogspot.com</td>\n",
       "      <td>[182871.0, 182969.0, 184223.0, 186002.0, 75989...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://3.bp.blogspot.com</td>\n",
       "      <td>[172889.0, 182969.0, 184356.0, 185688.0, 23699...</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://4.bp.blogspot.com</td>\n",
       "      <td>[47463.0, 170628.0, 182969.0, 184674.0, 185625...</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://4travel.jp</td>\n",
       "      <td>[1026.0, 1027.0, 1027.0, 1027.0, 1027.0, 2797....</td>\n",
       "      <td>8874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Hyperlink  \\\n",
       "0  http://1.bp.blogspot.com   \n",
       "1  http://2.bp.blogspot.com   \n",
       "2  http://3.bp.blogspot.com   \n",
       "3  http://4.bp.blogspot.com   \n",
       "4         http://4travel.jp   \n",
       "\n",
       "                                               Times  Length  \n",
       "0  [180906.0, 182723.0, 182969.0, 184891.0, 18535...      50  \n",
       "1  [182871.0, 182969.0, 184223.0, 186002.0, 75989...      48  \n",
       "2  [172889.0, 182969.0, 184356.0, 185688.0, 23699...      56  \n",
       "3  [47463.0, 170628.0, 182969.0, 184674.0, 185625...      56  \n",
       "4  [1026.0, 1027.0, 1027.0, 1027.0, 1027.0, 2797....    8874  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(data['Time'], density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8.20300100e-05, 3.62458184e-05, 1.14460479e-05, 1.14460479e-05,\n",
       "        1.14460479e-05, 3.81534930e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "        7.63069861e-06, 3.81534930e-06]),\n",
       " array([1.00000e+00, 5.95780e+03, 1.19146e+04, 1.78714e+04, 2.38282e+04,\n",
       "        2.97850e+04, 3.57418e+04, 4.16986e+04, 4.76554e+04, 5.36122e+04,\n",
       "        5.95690e+04]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(grouped['Length'], density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2678105.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_end = grouped['Times'].apply(np.max).max()\n",
    "t_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inter_times(t, t_end):\n",
    "    tau = np.diff(t, prepend=0.0, append=t_end)\n",
    "    return torch.tensor(tau, dtype=torch.float32, device=device)\n",
    "\n",
    "inter_times_list = [get_inter_times(t, t_end) for t in grouped['Times'].values]\n",
    "inter_times = pad_sequence(inter_times_list, batch_first=True)\n",
    "seq_lengths = torch.tensor(grouped['Length'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Os2rmqgaYxH"
   },
   "source": [
    "# Choose a parametric distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parametric distribution choosen was the Log-logistic distribution. The formulas were taken from [Wikipedia](https://en.wikipedia.org/wiki/Log-logistic_distribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its PDF, $f(x)$, is given as:\n",
    "$$f(x) = \\frac{(\\beta/\\alpha) \\cdot (x/\\alpha)^{\\beta -1}}{(1 + (x/\\alpha)^\\beta)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating $ln(f(x))$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\ln(f(x)) &= \\ln( \\frac{(\\beta/\\alpha) \\cdot (x/\\alpha)^{\\beta -1}}{(1 + (x/\\alpha)^\\beta)^2}) \\\\\n",
    "&= \\ln((\\beta / \\alpha) \\cdot (x /\\alpha)^{\\beta - 1}) - \\ln(1 + (x / \\alpha)^\\beta)^2 \\\\\n",
    "&= \\ln(\\beta / \\alpha) + \\ln((x/\\alpha)^{\\beta - 1}) - 2\\cdot \\ln(1 + (x / \\alpha)^\\beta) \\\\\n",
    "&= \\ln(\\beta) - \\ln(\\alpha) + (\\beta - 1)\\cdot(\\ln(x) - \\ln(\\alpha)) - 2\\cdot \\ln(1 + (x/ \\alpha)^\\beta)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its survival function, $S(x)$, is given as \n",
    "\n",
    "$$S(x) = \\frac{1}{1 + (x / \\alpha)^{\\beta}}$$\n",
    "\n",
    "Calculating $\\ln(S(x))$:\n",
    "\n",
    "\\begin{align*}\n",
    "\\ln(S(x)) &= \\ln(\\frac{1}{1 + (x / \\alpha)^{\\beta}} \\\\\n",
    "&= \\ln(1) - \\ln(1 + (x / \\alpha)^{\\beta}) \\\\\n",
    "&= - \\ln(1 + (x / \\alpha)^{\\beta})\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to compute its inverse, we solve $e^{z} = S(x)$:\n",
    "\n",
    "\\begin{align*}\n",
    "e^{z} &= S(x) \\\\\n",
    "\\ln(e^{z}) &= \\ln(S(x)) \\\\\n",
    "z &= -\\ln(1 + (x / \\alpha)^{\\beta}) \\\\\n",
    "-z &= \\ln(1 + (x / \\alpha)^{\\beta}) \\\\\n",
    "e^{-z} &= 1 + (x / \\alpha)^{\\beta} \\\\\n",
    "e^{-z} - 1 &= (x / \\alpha)^{\\beta} \\\\\n",
    "(e^{-z} - 1)^{1/ \\beta} &= x / \\alpha \\\\\n",
    "(e^{-z} - 1)^{1 / \\beta} \\cdot \\alpha &= x\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bhWhF25gaYxH"
   },
   "outputs": [],
   "source": [
    "class LogLogistic:\n",
    "    \"\"\"Log-logistic distribution.\n",
    "\n",
    "    Args:\n",
    "        a: scale parameter a (strictly positive)\n",
    "        b: shape parameter b (strictly positive)\n",
    "        eps: Minimum value of x, used for numerical stability.\n",
    "    \"\"\"\n",
    "    def __init__(self, a, b, eps=1e-8):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.eps = eps\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        \"\"\"Logarithm of the probability density function log(f(x)).\"\"\"\n",
    "        # x must have the same shape as self.b and self.k\n",
    "        x = x.clamp_min(self.eps)  # pow is unstable for inputs close to 0\n",
    "        return (self.b.log() - self.a.log() + (self.b - 1)*(x.log() - self.a.log()) \n",
    "               -2*torch.log(1 + (x/self.a).pow(self.b)))\n",
    "\n",
    "    def log_survival(self, x):\n",
    "        \"\"\"Logarithm of the survival function log(S(x)).\"\"\"\n",
    "        x = x.clamp_min(self.eps)\n",
    "        return -(torch.log(1 + (x/self.a).pow(self.b)))\n",
    "\n",
    "    def log_survival_inverse(self, z):\n",
    "        \"\"\"Solves exp(-z) = S(x) for x\"\"\"\n",
    "        z = z.clamp_min(self.eps)\n",
    "        return ((torch.exp(-z) - 1).pow(self.b.reciprocal())) * self.a\n",
    "\n",
    "    def sample(self, sample_shape=torch.Size()):\n",
    "        \"\"\"Generate a sample from the distribution.\"\"\"\n",
    "        # We do sampling using the inverse transform method\n",
    "        # If z ~ Expo(1), then solving exp(-z) = S(x) for x produces\n",
    "        # a sample from the distribution with survival function S\n",
    "        shape = torch.Size(sample_shape) + self.b.shape\n",
    "        z = torch.empty(shape).exponential_(1.0)\n",
    "        return self.log_survival_inverse(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuBur_XWaYxI"
   },
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Ml0ML_QVaYxJ"
   },
   "outputs": [],
   "source": [
    "class NeuralTPP(nn.Module):\n",
    "    \"\"\"A simple neural TPP model with an RNN encoder.\n",
    "\n",
    "    Args:\n",
    "        context_size: Size of the RNN hidden state.\n",
    "    \"\"\"\n",
    "    def __init__(self, context_size=32):\n",
    "        super().__init__()\n",
    "        self.context_size = context_size\n",
    "        # Used to embed the event history into a context vector\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=2,\n",
    "            hidden_size=context_size,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        # Used to obtain model parameters from the context vector\n",
    "        self.hypernet = nn.Linear(\n",
    "            in_features=context_size,\n",
    "            out_features=2,\n",
    "        )\n",
    "\n",
    "    def get_context(self, inter_times):\n",
    "        \"\"\"Get context embedding for each event in each sequence.\n",
    "\n",
    "        Args:\n",
    "            inter_times: Padded inter-event times, shape (B, L)\n",
    "\n",
    "        Returns:\n",
    "            context: Context vectors, shape (B, L, C)\n",
    "        \"\"\"\n",
    "        tau = inter_times.unsqueeze(-1)\n",
    "        # Clamp tau to avoid computing log(0) for padding and getting NaNs\n",
    "        log_tau = inter_times.clamp_min(1e-8).log().unsqueeze(-1)  # (B, L, 1)\n",
    "        rnn_input = torch.cat([tau, log_tau], dim=-1)\n",
    "        # The intial state is automatically set to zeros\n",
    "        rnn_output = self.rnn(rnn_input)[0]  # (B, L, C)\n",
    "        # Shift by one such that context[:, i] will be used\n",
    "        # to parametrize the distribution of inter_times[:, i]\n",
    "        context = F.pad(rnn_output[:, :-1, :], (0, 0, 1, 0))  # (B, L, C)\n",
    "        return context\n",
    "\n",
    "    def get_inter_time_distribution(self, context):\n",
    "        \"\"\"Get context embedding for each event in each sequence.\n",
    "\n",
    "        Args:\n",
    "            context: Context vectors, shape (B, L, C)\n",
    "\n",
    "        Returns:\n",
    "            dist: Conditional distribution over the inter-event times\n",
    "        \"\"\"\n",
    "        raw_params = self.hypernet(context)  # (B, L, 2)\n",
    "        b = F.softplus(raw_params[..., 0])  # (B, L)\n",
    "        k = F.softplus(raw_params[..., 1])  # (B, L)\n",
    "        return LogLogistic(a=b, b=k)\n",
    "\n",
    "    def nll_loss(self, inter_times, seq_lengths):\n",
    "        \"\"\"Compute negative log-likelihood for a batch of sequences.\n",
    "\n",
    "        Args:\n",
    "            inter_times: Padded inter_event times, shape (B, L)\n",
    "            seq_lengths: Number of events in each sequence, shape (B,)\n",
    "\n",
    "        Returns:\n",
    "            log_p: Log-likelihood for each sequence, shape (B,)\n",
    "        \"\"\"\n",
    "        context = self.get_context(inter_times)  # (B, L, C)\n",
    "        inter_time_dist = self.get_inter_time_distribution(context)\n",
    "\n",
    "        log_pdf = inter_time_dist.log_prob(inter_times)  # (B, L)\n",
    "        # Construct a boolean mask that selects observed events\n",
    "        arange = torch.arange(inter_times.shape[1], device=seq_lengths.device)\n",
    "        mask = (arange[None, :] < seq_lengths[:, None]).float()  # (B, L)\n",
    "        log_like = (log_pdf * mask).sum(-1)  # (B,)\n",
    "\n",
    "        log_surv = inter_time_dist.log_survival(inter_times)  # (B, L)\n",
    "        end_idx = seq_lengths.unsqueeze(-1)  # (B, 1)\n",
    "        log_surv_last = torch.gather(log_surv, dim=-1, index=end_idx)  # (B, 1)\n",
    "        log_like += log_surv_last.squeeze(-1)  # (B,)\n",
    "        return -log_like\n",
    "\n",
    "    def sample(self, batch_size, t_end):\n",
    "        \"\"\"Generate an event sequence from the TPP.\n",
    "\n",
    "        Args:\n",
    "            batch_size: Number of samples to generate in parallel.\n",
    "            t_end: Time until which the TPP is simulated.\n",
    "\n",
    "        Returns:\n",
    "            inter_times: Padded inter-event times, shape (B, L)\n",
    "            seq_lengths: Number of events in each sequence, shape (B,)\n",
    "        \"\"\"\n",
    "        inter_times = torch.empty([batch_size, 0])\n",
    "        next_context = torch.zeros(batch_size, 1, self.context_size)\n",
    "        generated = False\n",
    "        cnt = 0\n",
    "        while not generated:\n",
    "            cnt+=1\n",
    "            if cnt % 100 == 0:\n",
    "                print(\"iteration: \", cnt)\n",
    "            inter_time_dist = self.get_inter_time_distribution(next_context)\n",
    "            next_inter_times = inter_time_dist.sample()  # (B, 1)\n",
    "            inter_times = torch.cat([inter_times, next_inter_times], dim=1)  # (B, L)\n",
    "\n",
    "            # Obtain the next context vector\n",
    "            tau = next_inter_times.unsqueeze(-1)  # (B, 1, 1)\n",
    "            log_tau = next_inter_times.clamp_min(1e-8).log().unsqueeze(-1)  # (B, 1, 1)\n",
    "            rnn_input = torch.cat([tau, log_tau], dim=-1)  # (B, 1, 2)\n",
    "            next_context = self.rnn(rnn_input, next_context.transpose(0, 1))[0]  # (B, 1, C)\n",
    "\n",
    "            # Check if the end of the interval has been reached\n",
    "            generated = inter_times.sum(-1).min() >= t_end\n",
    "        # Convert the sample to the same format as our input data\n",
    "        arrival_times = inter_times.cumsum(-1)\n",
    "        seq_lengths = (arrival_times < t_end).sum(-1).long()\n",
    "        inter_times = arrival_times - F.pad(arrival_times, (1, 0))[..., :-1]\n",
    "        return inter_times, seq_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZfyr_o8aYxK"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter_times.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Qb8f1GdlaYxL",
    "outputId": "abc3ba9e-0363-49d6-cead-b0fd8e4e1fcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss = -0.014\n",
      "Epoch 50: loss = -0.032\n",
      "Epoch 100: loss = -0.033\n",
      "Epoch 150: loss = -0.034\n",
      "Epoch 200: loss = -0.034\n",
      "Epoch 250: loss = -0.034\n",
      "Epoch 300: loss = -0.034\n"
     ]
    }
   ],
   "source": [
    "model = NeuralTPP()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "\n",
    "max_epochs = 300\n",
    "for epoch in range(max_epochs + 1):\n",
    "    opt.zero_grad()\n",
    "    loss = model.nll_loss(inter_times, seq_lengths).mean() / t_end\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch}: loss = {loss.item():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPQJvlRgaYxL"
   },
   "source": [
    "# Sample event sequences from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrival_times_list = grouped['Times'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ntAUBEOfaYxM"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    gen_inter_times, gen_seq_lengths = model.sample(1000, t_end)\n",
    "gen_arrival_times = gen_inter_times.cumsum(-1)\n",
    "generated_sequences = []\n",
    "for i in range(gen_arrival_times.shape[0]):\n",
    "    t = gen_arrival_times[i, :gen_seq_lengths[i]].cpu().numpy()\n",
    "    generated_sequences.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NMg_MO4XaYxM"
   },
   "outputs": [],
   "source": [
    "seq_lengths = seq_lengths.cpu().numpy()\n",
    "gen_seq_lengths = gen_seq_lengths.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mf0aCawGaYxM",
    "outputId": "708d1acd-72c0-4f38-df1e-d15bdb4d45f6"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=[8, 4.5], dpi=200, nrows=2, ncols=2)\n",
    "plt.subplots_adjust(hspace=0.1)\n",
    "for idx, t in enumerate(arrival_times_list[:10]):\n",
    "    axes[0, 0].scatter(t, np.ones_like(t) * idx, alpha=0.5, c='C0', marker=\"|\")\n",
    "axes[0, 0].set_ylabel(\"Real sequence #\", fontsize=7)\n",
    "axes[0, 0].set_yticks(np.arange(10));\n",
    "axes[0, 0].set_title(\"Visualization of arrival times\", fontsize=9)\n",
    "\n",
    "\n",
    "for idx, t in enumerate(generated_sequences[:10]):\n",
    "    axes[1, 0].scatter(t, np.ones_like(t) * idx, alpha=0.5, c='C1', marker=\"|\")\n",
    "axes[1, 0].set_xlabel(\"Time\", fontsize=7)\n",
    "axes[1, 0].set_ylabel(\"Generated sequence #\", fontsize=7)\n",
    "axes[1, 0].set_yticks(np.arange(10))\n",
    "axes[0, 0].set_xticklabels([])\n",
    "\n",
    "for ax in np.ravel(axes):\n",
    "    ax.tick_params(axis='x', labelsize=7)\n",
    "    ax.tick_params(axis='y', labelsize=7)\n",
    "\n",
    "axes[0, 1].set_title(\"Distribution of sequence lengths\", fontsize=9)\n",
    "q_min = min(seq_lengths.min(), gen_seq_lengths.min())\n",
    "q_max = max(seq_lengths.max(), gen_seq_lengths.max())\n",
    "axes[0, 1].hist(seq_lengths, 30, alpha=0.8, color=\"C0\", range=(q_min, q_max), label=\"Real data\");\n",
    "axes[0, 1].set_ylabel(\"Frequency\", fontsize=7)\n",
    "axes[0, 1].set_xticklabels([])\n",
    "\n",
    "axes[1, 1].hist(gen_seq_lengths, 30, alpha=0.8, color=\"C1\", range=(q_min, q_max), label=\"Generated by the model\");\n",
    "axes[1, 1].set_xlabel(r\"Sequence length\", fontsize=7)\n",
    "axes[1, 1].set_ylabel(\"Frequency\", fontsize=7)\n",
    "\n",
    "fig.legend(loc=\"lower center\", ncol=2, fontsize=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "neuraltpp",
   "language": "python",
   "name": "neuraltpp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
